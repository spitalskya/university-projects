from typing import Optional, Callable
import math
import random
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np

def generate_polygon_coordinates(num_sides, center=(0, 0), radius=1):
    # generated by ChatGPT with prompt: "generate coordinates for vertices of polygon as python list"
    cx, cy = center  # Center of the pentagon
    vertices = []
    
    for i in range(num_sides):
        angle = 2 * math.pi * i / num_sides  # Angle for each vertex
        x = cx + radius * math.cos(angle)  # X coordinate
        y = cy + radius * math.sin(angle)  # Y coordinate
        vertices.append((x, y))
    
    return vertices


def PSO_Steiner_tree(points: list[tuple[float, float]], m: Optional[int] = None,
                     particles_count: int = 20, max_iters: int = 1000,
                     w_start: float = 0.9, w_fin: float = 0.4,
                     phi_1: float = 1, phi_2: float = 2,
                     show_progress: bool = True, show_result: bool = True
                     ) -> tuple[np.ndarray, float]:
    """Solving Euclidean Steiner tree problem through particle swarm optimization

    Args:
        points (list[tuple[float, float]]): locations of terminals (fixed vertices of a graph)
        m (Optional[int], optional): how many verticies to add, if None, then n-2. Defaults to None.
        particles_count (int, optional): how many particles should take part in optimization. Defaults to 20.
        max_iters (int, optional): how many iterations to perform. Defaults to 1000.
        w_start (float, optional): starting inertia parameter. Defaults to 0.9.
        w_fin (float, optional): ending inertia parameter. Defaults to 0.4.
        phi_1 (float, optional): coefficient for personal component. Defaults to 1.
        phi_2 (float, optional): coefficient for social component. Defaults to 2.
        show_progress (bool, optional): whether to display how particles looked throughout the iterations. Defaults to True.
        show_result (bool, optional): whether to display optimal solution and average fitness through iterations. Defaults to True.

    Returns:
        tuple[np.ndarray, float]: pair of values
            first value: optimal solution in form of list of m 2D points (x1, y1,...,xm, ym)
            second value: fitness value for the optimal solution
    """
    
    def objective_function(particle: np.ndarray) -> float:
        """Objective function for minimization problem
        Creates graph from `points` and coordinates stored in `particle`.
        Calculates the sum of weights in minimum spanning tree.

        Args:
            particle (np.ndarray): particle representing locations of m vertices

        Returns:
            float: sum of weights of MST
        """
        # create the minimum spanning tree
        mst: nx.Graph = nx.minimum_spanning_tree(create_graph(particle))
        
        # calculate the sum of its weights
        return sum(data['weight'] for _, _, data in mst.edges(data=True))
    
    
    def initialize_particle() -> np.ndarray:
        """Creates one particle representing the locations of m vertices
        Locations of vertices are "drawn" m times from 2D uniform distribution,
        where first coordinate ranges from minimum x value in the `points` to maximum x value,
        similarly the second coordinate and y values. 

        Returns:
            np.ndarray: random particle
        """
        # extract the boundaries from points
        min_x, max_x = min(points, key=lambda p: p[0])[0], max(points, key=lambda p: p[0])[0]
        min_y, max_y = min(points, key=lambda p: p[1])[1], max(points, key=lambda p: p[1])[1]
        
        # draw m times from 2D uniform distribution with given boundaries
        return np.random.uniform(low=[min_x, min_y]*m, high=[max_x, max_y]*m, size=2*m)
        
        
    def create_dict_of_vertex_positions(particle: np.ndarray) -> dict[int, tuple[float, float]]:
        """Creates a dictionary for all vertices in current solution,
        where key is the vertex and value is its 2D location

        Args:
            particle (np.ndarray): current solution (2D locations of m vertices)

        Returns:
            dict[int, tuple[float, float]]: each vertex mapped to its location on the plane
        """
        # fill the dictionary with fixed vertices 
        vertex_positions: dict[int, tuple[float, float]] = {
            i: point for i, point in enumerate(points)
        }
        
        # fill the dictionary with vertices stored in current particle
        for j in range(m):
            point: tuple[float, float] = tuple(particle[2*j : 2*j + 2])
            vertex_positions[j + len(points)] = point
        
        # return the dictionary
        return vertex_positions
    
    
    def create_graph(particle: np.ndarray) -> nx.Graph:
        """Creates a complete weighted graph from fixed vertices and m vertices stored in particle.
        Weights are euclidean distances between the vertices
        
        Args:
            particle (np.ndarray): locations of m additional vertices

        Returns:
            nx.Graph: complete weighted graph
        """
        
        # define the function for euclidean distance between two 2D points
        euclidean_distance: Callable[[tuple[float, float], tuple[float, float]], float] 
        euclidean_distance = lambda p1, p2: math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)
        
        # get the locations of the nodes in concise format
        vertex_positions: dict[int, tuple[float, float]] = create_dict_of_vertex_positions(particle)
        
        # create the graph
        graph: nx.Graph = nx.Graph()
        
        # fill the graph with vertices and edges
        for u in vertex_positions:
            for v in vertex_positions:
                if u == v: continue     # no loops
                
                # calculate weight of the edge between vertices u and v as their euclidean distance
                distance = euclidean_distance(vertex_positions[u], vertex_positions[v])
                
                # add the edge to the graph
                graph.add_edge(u, v, weight=distance)
        
        # return the graph
        return graph
    
    
    def plot_particle(particle: np.ndarray, ax: plt.Axes, 
                      alpha: float = 1, with_labels: bool = True, vertex_size: int = 500
                      ) -> None:
        """Plots current graph with current particle on given ax

        Args:
            particle (np.ndarray): locations of m points to add to the fixed points
            ax (plt.Axes): figure to draw to
            alpha (float, optional): transparency of the drawing. Defaults to 1.
            with_labels (bool, optional): whether to write labels on vertices and edges. Defaults to True.
            vertex_size (int, optional): size of the vertex drawing. Defaults to 500.
        """
        # get positions of all vertices
        vertex_positions: dict[int, tuple[float, float]] = create_dict_of_vertex_positions(particle)
        
        # create minimum spanning tree to be drawn
        mst: nx.Graph = nx.minimum_spanning_tree(create_graph(particle))
        
        # differentiate the colors of fixed points and points in `particle`
        colors = ["lightblue" if i < len(points) else "lightgreen" for i in vertex_positions]
        
        # extract weights for edge labels, if they ought to be displayed
        if with_labels:
            edge_labels = {(u, v): f'{d["weight"]:.2f}' for u, v, d in mst.edges(data=True)}
        else:
            edge_labels = False
        
        # draw the graph
        nx.draw(
            mst, pos=vertex_positions, with_labels=with_labels, node_color=colors, node_size=vertex_size, font_size=10,
            ax=ax, alpha=alpha
            )
        nx.draw_networkx_edge_labels(
            mst, pos=vertex_positions, edge_labels=edge_labels, 
            ax=ax, alpha=alpha
        )
        
        
    # if no number of vertices to add is set, add n-2, 
    # because we know that optimal solution requires at most n-2 new vertices
    if m is None:
        m = len(points) - 2
    
    # initialize the random particles
    # each particle is of length 2m representing m points in 2D plane -> (x1, y1,..., xm, ym)
    particles: list[np.ndarray] = [initialize_particle() for _ in range(particles_count)]
    
    # initialize the velocities as zeros
    velocities: list[np.ndarray] = [np.zeros(shape=2*m) for _ in particles]
    
    # for each particle, store its personal best location and value of the objective function in that location
    personal_components: list[tuple[np.ndarray, float]] = [
        (particle.copy(), objective_function(particle)) for particle in particles
        ]
    
    # store the best location and so far minimal value of the objective function
    social_component: tuple[np.ndarray, float] = min(personal_components, key=lambda x: x[1])

    # list to store average fitness of each iteration for visualization purposes
    fitnesses: list[float] = []
    
    # figure for visualization of particles 10 times throughout the run
    if show_progress:
        fig, axs = plt.subplots(2, 5, figsize=(16, 8))
        axs = axs.ravel()
    
    # iterate
    for it in range(max_iters):       
        # add the average fitness to `fitnesses` list
        fitnesses.append(sum([p[1] for p in personal_components]) / len(personal_components))
        
        # visualize all particles 10 times throughout the run, displayed at the end
        if show_progress and it % int(max_iters / 10) == 0:   
            ax: plt.Axes = axs[it // int(max_iters / 10)]
            for particle in particles:
                plot_particle(particle, ax=ax, alpha=0.5, with_labels=False, vertex_size=100)
            
            ax.set_title(f"Particles in {it}-th iteration,\naverage fitness={fitnesses[-1]:.3f}")    
        
        # update the inertia for the velocity
        w: float = it * (w_fin - w_start) / max_iters + w_start
        
        # update each particle
        for i in range(particles_count):
            # "draw" coefficients for personal and social component from U(0, 1) 
            u1, u2 = np.random.random(size=2)
            
            # update the velocity
            velocities[i] = (
                w*velocities[i]                                                 # inertia
                + phi_1 * u1 * (personal_components[i][0] - particles[i])       # personal component
                + phi_2 * u2 * (social_component[0] - particles[i]))            # social component
            
            # update the location of the particle by its velocity
            particles[i] = particles[i] + velocities[i]
            
            # calculate the fitness of the moved particle
            new_particle_fitness = objective_function(particles[i])
            
            # if the fitness of the moved particle is its best so far, update its personal component
            if new_particle_fitness < personal_components[i][1]:
                personal_components[i] = particles[i].copy(), new_particle_fitness
                
            # if the fitness of the moved particle is the best of all so far, update the social component
            if new_particle_fitness < social_component[1]:
                social_component = (particles[i].copy(), new_particle_fitness)   
        
    # visualize particles throughout the generations
    if show_progress:
        fig.suptitle("Visualization of particles throughout iterations", fontsize=16)
        plt.tight_layout()
        plt.show()
    
    # visualization of the results -> average fitnesses in iterations and optimal solution
    if show_result:
        _, axs = plt.subplots(1, 2, figsize=(10, 5))
        
        axs[0].plot(fitnesses)
        axs[0].set_title("Average fitness in iterations")
        axs[0].set_xlabel("iteration")
        axs[0].set_ylabel("average fitness")
        
        plot_particle(social_component[0], ax=axs[1])
        axs[1].set_title(f"Optimal solution found\noptimal fitness = {social_component[1]:.3f}")
        plt.show()
        
    # return the optimal solution and its fitness
    return social_component    


def binary_search_PSO_Steiner_tree(points: list[tuple[float, float]], max_iters: int = 1000, 
                  eps: float = 1e-4) -> tuple[np.ndarray, float]:
    """An attempt to find optimal number of vertices to be added for Steiner tree problem.
    It is a sort of binary search. We know that optimal solution can be found with m=n-2
    vertices. Therefore if we find same or lower (my algorithm tends to overshoot the fitness
    with m too high) fitness value as my algorithm returns for m=n-2, we know we still have 
    a good approximation of an optimal solution. If fitness for some m is higher, we need to 
    increase it.

    Args:
        points (list[tuple[float, float]]): locations of vertices
        max_iters (int, optional): maximum number of iterations of PSO. Defaults to 1000.
        eps (float, optional): if absolute difference is smaller than eps, we say the values are the same. 
            Defaults to 1e-4.

    Returns:
        tuple[np.ndarray, float, int]: 
            first value: locations of m vertices to be added
            second value: fitness value for found optimal solution
            third value: optimal number of vertices to add
    """
    # we know that optimal m âˆˆ [0, n-2]
    left = 0
    right = len(points) - 2
    
    # with m = n-2, we can get an optimal fitness which we will try to achieve with smaller m
    # however, my PSO tends to overshoot the optimal fitness if m is higher than necessary,
    # so we may find a solution with lower fitness with smaller m even though it should be impossible
    best_fitness = PSO_Steiner_tree(points, max_iters=max_iters, show_progress=False, show_result=False)[1]
    
    # search for optimal m
    while right != left:
        print(f"m \u2208 [{left}, {right}]")

        m = (left + right) // 2
        _, fitness = PSO_Steiner_tree(points, m=m, max_iters=max_iters, show_progress=False, show_result=False)

        if fitness - best_fitness < eps:
            # found same or better fitness than the one with m=n-2
            # no point in searching through higher m
            best_fitness = fitness
            right = m
        else:
            # found fitness is too big, we need to increase m
            left = m + 1

    optimal_m = left
    return *PSO_Steiner_tree(points, m=optimal_m, max_iters=max_iters), optimal_m
    
    
def main() -> None:
    """# find the solution to the Euclidean Steiner tree problem for triangle, square,...,heptagon
    # number of vertices added is always n-2, where n is the number of terminals
    for shape in (generate_polygon_coordinates(num_sides=i) for i in range(3, 8)):
        PSO_Steiner_tree(shape)
    
    """
    """Below is an attempt to find an optimal number of vertices to add
    with an adaptation of binary search.
    It doesn't work that well, however sometimes yields pretty results, 
    therefore I include it. 
    (takes up to 20 seconds with my experience)  
    """"""
    # 7 random points in [0, 10]x[0, 10]
    sol = binary_search_PSO_Steiner_tree([(random.random() * 10, random.random() * 10) for _ in range(7)])
    print(f"Solution: {sol[0]}")
    print(f"Fitness: {sol[1]}")
    print(f"Optimal m: {sol[2]}\n")
    
    # 10 random points in [0, 10]x[0, 10]
    sol = binary_search_PSO_Steiner_tree([(random.random() * 10, random.random() * 10) for _ in range(10)])
    """
    
    sol = PSO_Steiner_tree([(random.random() * 10, random.random() * 10) for _ in range(10)])
    print(f"Solution: {sol[0]}")
    print(f"Fitness: {sol[1]}")
    print(f"Optimal m: {sol[2]}")
    
    # potential fix -> remove added vertices that in minimum spanning tree have degree equal to 2
    
if __name__ == "__main__":
    main()
